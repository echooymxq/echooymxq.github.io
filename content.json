{"pages":[{"title":"Me","text":"","link":"/about/index.html"},{"title":"categories","text":"","link":"/categories/index.html"},{"title":"Project","text":"","link":"/project/index.html"},{"title":"Tags","text":"","link":"/tags/index.html"}],"posts":[{"title":"谈谈我对Reactive Programming的理解","text":"Microsoft于2012年的时候在.NET生态中实现了反应式扩展库，简称ReactiveX或Rx。跟着RxJava又开发了JVM上的实现。之后Pivotal、Netflix、LightBend和Twitter等厂商联合建立了Reactive Streams，并在2015-04-28发布1.0版本。并由Doug Lea通过JEP-266 More Concurrency Updates提案增加了Flow API包括了在JDK9中。 或许以前你没怎么听说过Reactive Programming，但随着Spring5的发布，WebFlux、R2DBC、RSocket等各种名词层出不穷，Reactive相关的文章不断，基于国内主要使用Spring全家桶居多，一下子Reactive Programming成为热门技术，似乎是Spring将Reactive Programming带到了新高度，但其实主流的微服务框架Helidon、Micronaut、Quarkus和Vert.x等都支持Reactive Programming。 什么是Reactive Programming?这是在最开始学习Reactive Programming（后文统称为反应式编程）的时候问得最多的问题了，根据维基百科的定义： 反应式编程是一种面向数据流和变化传播的声明式编程范式。 https://en.wikipedia.org/wiki/Reactive_programming 看完介绍可能还是难以理解具体什么是反应式编程，因为它没有更详细的定义描述，没有结合具体编程语言进行讲解，反应式编程解决了什么问题？我们为什么要使用反应式编程？带着这些问题，从我自己的角度谈谈对反应式编程的理解。 首先反应式编程主要面向的是数据编程，而非面向逻辑编程。数据流在Java中对应Stream，涉及到流就会有过滤、转换、聚合和拆分，还有缓冲、调整流速率操作等等。变化传播类比观察者模式(Observer Pattern)，当数据发生改变时，才会对其进行响应。另外变化传播也意味着异步非阻塞，Java使用Future表示异步任务结果，在获取执行结果时可能导致阻塞。而CompletableFuture能够真正的进行异步非阻塞操作，一旦任务完成触发回调执行下游方法，并可链接多个操作。 那么我的理解就是在Java中反应式编程(Reactive) = 数据流(Stream) + 异步(CompletableFuture) + 背压(BackPressure)。我们没办法使用Java的Stream和CompletableFuture很好进行数据流的异步编程。首先Stream使用Iterator进行数据读取，虽然提供了parallel并行操作，但是其终止操作依旧是阻塞的。Stream的数据是静态的，无法动态生成，另外缺少部分高阶操作如缓冲、窗口等。 1234Stream.of(1, 2, 3) .parallel() .map(String::valueOf) // paralleled .collect(Collectors.toList()); // blocked CompletableFuture支持异步链式回调，并可指定Executor对应执行线程池，虽然提供了allOf方法，但无法对多个(流)异步操作进行组合处理。anyOf为当其中一个操作完成时结束，不能中断其它未完成的操作。 123456789101112131415CompletableFuture .allOf(f1, f2, ...) .thenApply(tt -&gt; { // where my result? // need result? Object result1 = f1.join(); Object result2 = f2.join(); });CompletableFuture .anyOf(f1, f2, ...) .thenApply(tt -&gt; { if (!f2.isDone()) { f2.cancel(true); // CompletableFuture cancel not working. } }); BackPressure指上游生产者的生产速率大于下游消费者的消费速率时的流控处理。一种是消费者根据自身能力使用Pull的方式进行数据获取；另一种则是生产者调整流控，当消费者来不及消费时，将数据进行缓冲、丢弃等。 那么反应式编程解决了什么问题呢？我们为什么要使用反应式编程？我们以Tomcat为例，Tomcat默认采用一个请求一个线程的方式，假设配置的线程池大小为100，响应时间为100ms/r，那么系统的QPS能够达到1000r/s。假定在固定线程池大小不变的情况下，因为更多的线程意味着更多的上下文切换和内存消耗，如果因为一些阻塞操作如IO等导致线程阻塞，加大了响应时间，那么整体系统的QPS将降低。另外通常我们的业务系统的基本流程为请求(解析Json) -&gt; 数据交换(Database) -&gt; 响应(组装Json)，而我们可以使用反应式编程，把请求当作数据流，基于数据流，根据反应式编程框架提供的操作符，声明式的组装业务流程和逻辑，并且包含高阶的并发抽象，异步编程会更容易，更充分地利用系统资源。我们此处暂不论Servlet异步API，因为它同样面临上面提到的异步编程困境。 反应式编程不是银弹，它的缺点？ 可维护性代码的关注重点由以前的逻辑代码转为围绕反应式编程框架提供的操作符。 排查异常困难当代码出现异常时，异常堆栈可能全是操作符的嵌套调用，无法得知真正的异常位置，虽然部分反应式框架提供了调试工具，依旧加大了异常排查难度。 编程难度反应式编程异步非阻塞的特性，使得原来那些如同步监控指标统计或依赖线程上下文的操作都将不能工作，另外反应式编程通常和函数式编程结合，反应式框架本身就有一定的学习成本，降低开发效率。 Reactive Programming和Reactive System的区别？ Reactive Programming Reactive Programming是一种面向数据流的异步编程范式，通常应用在单个组件或者服务上。 Reactive System Reactive System 则是系统级别的，比如分布式系统。反应式宣言描述了符合反应式系统的设计原则，其中包括Responsive、Resilient、Elastic和Message Driven几个特性。 总结Reactive Programming是非常有意思的，并且值得所有开发人员学习，但是你可以在工程上完全不使用Reactive Programming，这取决于你的系统能够从中获取什么，并承受相应带来的弊端。但是例如在一些负载均衡代理方面的应用，Reactive Programming有极大的优势，或者涉及到一些数据流编排，如多个微服务API链式调用，Reactive Programming能够很轻松的表达异步调用。 Reference https://www.reactive-streams.org/ http://openjdk.java.net/jeps/266 https://en.wikipedia.org/wiki/Observer_pattern https://www.reactivemanifesto.org/ https://www.reactive.foundation/","link":"/2022/04/23/reactive/reactive_programming/"},{"title":"使用Reactor进行反应式编程(四)","text":"","link":"/2022/04/26/reactor/backpressure/"},{"title":"使用Reactor进行反应式编程(五)","text":"在命令式编程中，我们习惯了在一个线程里面编写代码执行逻辑，这个时候往往依赖ThreadLocal将数据和线程进行绑定，例如Logback中的MDC就是使用ThreadLocal来存储日志相关信息的。前面我们提到了Reactor是并发不可知论的，在反应式编程中，业务代码中流的执行可能经常面临着线程的切换，在Reactor中再依赖ThreadLocal，就变得不会有多大作用了。而Reactor提供了另一个类似于ThreadLocal的特性Context，它不与线程相关，而是针对于Flux、Mono，这一节我们主要讲讲Reactor中的Context。 我们先看下在Reactor中ThreadLocal有什么问题，如下所示： 123456789static final ThreadLocal&lt;String&gt; USER_ID = new ThreadLocal&lt;&gt;();@Testpublic void threadLocal() { USER_ID.set(&quot;echooymxq&quot;); Mono.just(&quot;Hello %s&quot;) .delayElement(Duration.ofMillis(100)) // 使用Scheduler#parallel .doOnNext(greeting -&gt; System.out.printf((greeting) + &quot;%n&quot;, USER_ID.get())) // Hello null .block();} 这里有什么问题？ 先使用USER_ID设置值，当前与main线程绑定 提交任务到parallel调度器，延时100ms 调用doOnNext进行信息打印，当前执行线程为parallel线程，原线程上下文丢失，变量值为空 对应使用Reactor的Context的版本，如下所示： 1234567891011@Testpublic void context() { Mono.just(&quot;Hello %s&quot;) .delayElement(Duration.ofMillis(100)) .transform(flux -&gt; Mono.deferContextual(ctx -&gt; // Hello echooymxq flux.doOnNext(greeting -&gt; System.out.printf((greeting) + &quot;%n&quot;, (String)ctx.get(&quot;name&quot;)))) ) .contextWrite(Context.of(&quot;name&quot;, &quot;echooymxq&quot;)) .block();} Context类似于一个Map接口，用于存储键值对。它并不是Reactive Stream所规定的，而是Reactor除了传播事件信号以外，作为在操作符间传播上下文信息的一种特性。Reactor中的CoreSubscriber接口中包含一个currentContext方法，默认提供一个空的Context。Context是与Subscriber相绑定的，上游的操作符是通过下游的Subscriber来访问的，而下游的操作符是不能看到上游设置的Context。 12345678910111213141516171819@Testpublic void contextV1() { String key = &quot;message&quot;; Mono&lt;String&gt; r = Mono.just(&quot;Hello&quot;) .contextWrite(ctx -&gt; ctx.put(key, &quot;Reactor1&quot;)) // Context只能被上游操作符看到 .flatMap(s -&gt; Mono.deferContextual(ctx -&gt; { String s1 = s + &quot; &quot; + ctx.get(key); // Hello Reactor2 return Mono.just(s1); })) .contextWrite(ctx -&gt; ctx.put(key, &quot;Reactor2&quot;)) // 不变性，返回一个新的Context，此时为message:Reactor2 .flatMap(s -&gt; Mono.deferContextual(ctx -&gt; { String s1 = s + &quot; &quot; + ctx.get(key); // Hello Reactor2 World return Mono.just(s1); })) .contextWrite(ctx -&gt; ctx.put(key, &quot;World&quot;)); // 返回一个Context，此时message:World StepVerifier.create(r) .expectNext(&quot;Hello Reactor2 World&quot;) .verifyComplete();} 总结Reference https://github.com/echooymxq/reactive-study https://projectreactor.io/ https://easywheelsoft.github.io/reactor-core-zh/ https://projectreactor.io/docs/core/release/reference/","link":"/2022/04/26/reactor/context/"},{"title":"使用Reactor进行反应式编程(七)","text":"","link":"/2022/05/02/reactor/debug/"},{"title":"使用Reactor进行反应式编程(六)","text":"","link":"/2022/05/01/reactor/fusion/"},{"title":"使用Reactor进行反应式编程(三)","text":"我们都知道Reactive Stream主要包含几个接口Publisher、Subscriber、Subscription和Processor，其中Processor比较特殊，继承了Publisher和Subscriber，表示即可以是生产者也可以是订阅者，这一节就来讲讲Reactor中的Processor。 虽然Processor具有生产者和订阅者的语义，但是Reactor中的Processor通常并不是作为一个订阅者来使用的，它们被当成是暴露为一种Flux或Mono给下游的方式，同时以编程的方式进行下发元素，如下所示： 1234UnicastProcessor&lt;String&gt; processor = UnicastProcessor.create();processor.onNext(&quot;1&quot;);processor.onComplete();processor.asFlux().subscribe(System.out::println); 这里就会存在一个隐患，如果开发者直接通过Subscriber#onNext来进行下发元素，为了符合Reactive Stream的规范(元素One-by-One)，就需要外部进行额外的同步操作，而这一点通常被开发者忽略掉，从而导致并发问题。虽然可以使用FluxProcessor#sink()创建一个线性的FluxSink来避免这个问题，但是对开发者来说仍然不太方便。从3.4.0开始，官方开始引入Sinks，可以创建One、Empty、Many这三个具有Flux或Mono语义的接口实现，同时标注所有的相关Processor实现为Deprecated(过时)，并会在下个大版本3.5的时候移除。 OneOne具有Mono语义，表示最多能够下发零个或一个元素。使用One#asMono能够将其转化为一个Mono。可以调用emitValue、emitEmpty或emitError进行相关事件下发。 12345678@Testpublic void one() { Sinks.One&lt;String&gt; sink = Sinks.one(); sink.tryEmitValue(&quot;1&quot;); StepVerifier.create(sink.asMono()) .expectNext(&quot;1&quot;) .verifyComplete();} EmptyEmpty具有Mono语义，产生一个终止信号。使用Empty#asMono能够将其转化为一个Mono。调用emitEmpty、emitError下发complete或error信号。 1234567@Testpublic void empty() { final Sinks.Empty&lt;Void&gt; sink = Sinks.empty(); sink.tryEmitEmpty(); StepVerifier.create(sink.asMono().log()) .verifyComplete();} ManyMany具有Flux语义，表示能够下发多个元素，使用Many#asFlux能够将其转化一个Flux。可以调用emitNext、emitComplete或emitError进行相关事件下发。另外Many包括了三个实现unicast、multicast和replay。 unicast表示单播，只能允许一个订阅者。 123456// 只允许订阅一次public void sink_unicast_only_subscribe_once() { Sinks.Many&lt;String&gt; sink = Sinks.many().unicast().onBackpressureBuffer(); sink.asFlux().subscribe(); sink.asFlux().subscribe(); // UnicastProcessor allows only a single Subscriber} multicast表示多播，允许多个订阅者，并根据订阅者的情况(背压)使用onBackpressureBuffer、directAllOrNothing或directBestEffort进行广播下发元素。 onBackpressureBuffer表示根据请求最小的Subscriber来下发元素，下发不成功时将其缓存。1234567891011121314151617181920212223242526272829@Testpublic void sinkBackpressure() { final Sinks.Many&lt;String&gt; sink = Sinks.many().multicast().onBackpressureBuffer(); List&lt;String&gt; list1 = new ArrayList&lt;&gt;(), list2 = new ArrayList&lt;&gt;(); Sinks.EmitResult emitResult = sink.tryEmitNext(&quot;1&quot;); assertThat(emitResult == Sinks.EmitResult.OK).isTrue(); AtomicReference&lt;Subscription&gt; subscriptionRef = new AtomicReference&lt;&gt;(); sink.asFlux().subscribe(new BaseSubscriber&lt;&gt;() { @Override protected void hookOnSubscribe(Subscription s) { subscriptionRef.set(s); s.request(1); //只请求一个元素 } @Override protected void hookOnNext(String value) { list1.add(value); } }); sink.asFlux().subscribe(list2::add); emitResult = sink.tryEmitNext(&quot;2&quot;); // 第一个Subscriber只能消费1个元素，后续的元素下发将其缓存，并返回下发成功 assertThat(emitResult == Sinks.EmitResult.OK).isTrue(); emitResult = sink.tryEmitNext(&quot;3&quot;); assertThat(emitResult == Sinks.EmitResult.OK).isTrue(); assertThat(list1).isEqualTo(List.of(&quot;1&quot;)); // 元素缓存，下游并未获取到数据 assertThat(list2).isEqualTo(List.of()); subscriptionRef.get().request(2); // 当订阅者重新请求时，获取到缓存的数据 assertThat(list1).isEqualTo(List.of(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;)); assertThat(list2).isEqualTo(List.of(&quot;2&quot;, &quot;3&quot;));} 另外onBackpressureBuffer还涉及到bufferSize和autoCancel两个参数。bufferSize表示缓存第一个Subscriber订阅之前的元素数量。123456789@Testpublic void sink_backpressure_buffer() { // bufferSize 会根据传参 自行调整创建的queue的size Sinks.Many&lt;String&gt; sink = Sinks.many().multicast().onBackpressureBuffer(2); // adjustedBatchSize=8 IntStream.range(1, 10).forEach(s -&gt; sink.tryEmitNext(String.valueOf(s))); // 超过bufferSize的会被删掉 // 只会消费到1-8 sink.asFlux().subscribe(System.out::println);} autoCancel默认为true，表示如果有一个Subscriber取消订阅，那么整个Sinks都会终止。1234567891011@Testpublic void sink_autoCancel() { Sinks.Many&lt;String&gt; sink = Sinks.many().multicast().onBackpressureBuffer(Integer.MAX_VALUE, true); sink.tryEmitNext(&quot;1&quot;); AtomicReference&lt;Subscription&gt; subscription = new AtomicReference&lt;&gt;(); sink.asFlux().doOnSubscribe(subscription::set).subscribe(System.out::println); subscription.get().cancel(); // 取消订阅 sink.tryEmitNext(&quot;2&quot;); sink.asFlux().subscribe(System.out::println); //订阅并不会接收到元素，因为sink已被取消，可设置autoCancel为false，则不会对sink进行取消 assertThat(sink.scan(Scannable.Attr.CANCELLED)).isTrue();} directAllOrNothing为当没有订阅者时下发会失败，且不会缓存元素，另外只要任何一个订阅者不能处理元素，也会失败。1234567891011121314151617181920212223242526@Testpublic void sinkDirectAllOrNothing() { final Sinks.Many&lt;String&gt; sink = Sinks.many().multicast().directAllOrNothing(); List&lt;String&gt; list1 = new ArrayList&lt;&gt;(), list2 = new ArrayList&lt;&gt;(); Sinks.EmitResult emitResult = sink.tryEmitNext(&quot;1&quot;); // 没有订阅者时失败，直接删除元素 assertThat(emitResult == Sinks.EmitResult.FAIL_ZERO_SUBSCRIBER).isTrue(); sink.asFlux().subscribe(new BaseSubscriber&lt;&gt;() { @Override protected void hookOnSubscribe(Subscription s) { s.request(1); } @Override protected void hookOnNext(String value) { list1.add(value); } }); sink.asFlux().subscribe(list2::add); emitResult = sink.tryEmitNext(&quot;2&quot;); assertThat(list1).isEqualTo(List.of(&quot;2&quot;)); assertThat(list2).isEqualTo(List.of(&quot;2&quot;)); assertThat(emitResult == Sinks.EmitResult.OK).isTrue(); emitResult = sink.tryEmitNext(&quot;3&quot;);// 第一个订阅者request(1)，表示只能接收处理一个元素，后续的再下发元素也会失败 assertThat(emitResult == Sinks.EmitResult.FAIL_OVERFLOW).isTrue(); assertThat(list1).isEqualTo(List.of(&quot;2&quot;)); assertThat(list2).isEqualTo(List.of(&quot;2&quot;));} directBestEffort为只要有任何一个订阅者能处理元素，下发就不会失败1234567891011121314151617181920212223242526@Testpublic void sinkDirectBestEffort() { final Sinks.Many&lt;String&gt; sink = Sinks.many().multicast().directBestEffort(); List&lt;String&gt; list1 = new ArrayList&lt;&gt;(), list2 = new ArrayList&lt;&gt;(); Sinks.EmitResult emitResult = sink.tryEmitNext(&quot;1&quot;); assertThat(emitResult == Sinks.EmitResult.FAIL_ZERO_SUBSCRIBER).isTrue(); sink.asFlux().subscribe(new BaseSubscriber&lt;&gt;() { @Override protected void hookOnSubscribe(Subscription s) { s.request(1); } @Override protected void hookOnNext(String value) { list1.add(value); } }); sink.asFlux().subscribe(list2::add); emitResult = sink.tryEmitNext(&quot;2&quot;); assertThat(emitResult == Sinks.EmitResult.OK).isTrue(); assertThat(list1).isEqualTo(List.of(&quot;2&quot;)); assertThat(list2).isEqualTo(List.of(&quot;2&quot;)); emitResult = sink.tryEmitNext(&quot;3&quot;); //只要有一个订阅者能处理元素，下发就不会失败 assertThat(emitResult == Sinks.EmitResult.OK).isTrue(); assertThat(list1).isEqualTo(List.of(&quot;2&quot;)); assertThat(list2).isEqualTo(List.of(&quot;2&quot;, &quot;3&quot;));} replay同时具备多播和重播。对比multicast，multicast的订阅者只能看到缓存的元素和最新下发的元素数据，而replay可以根据需要对所有数据或部分数据进行重播。 all表示对于新的Subscriber重播全部数据123456789101112@Testpublic void reply_all() { Sinks.Many&lt;String&gt; sink = Sinks.many().replay().all(); List&lt;String&gt; list1 = new ArrayList&lt;&gt;(), list2 = new ArrayList&lt;&gt;(); sink.tryEmitNext(&quot;1&quot;); sink.tryEmitNext(&quot;2&quot;); sink.asFlux().subscribe(list1::add); sink.tryEmitNext(&quot;3&quot;); sink.asFlux().subscribe(list2::add); assertThat(list1).isEqualTo(List.of(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;)); assertThat(list2).isEqualTo(List.of(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;));} limit表示对于新的Subscriber根据limit大小进行重播123456789101112@Testpublic void reply_limit() { Sinks.Many&lt;String&gt; sink = Sinks.many().replay().limit(2); List&lt;String&gt; list1 = new ArrayList&lt;&gt;(), list2 = new ArrayList&lt;&gt;(); sink.tryEmitNext(&quot;1&quot;); sink.tryEmitNext(&quot;2&quot;); sink.asFlux().subscribe(list1::add); sink.tryEmitNext(&quot;3&quot;); sink.asFlux().subscribe(list2::add); assertThat(list1).isEqualTo(List.of(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;)); assertThat(list2).isEqualTo(List.of(&quot;2&quot;, &quot;3&quot;));} latest表示对于新的Subscriber只重播最近的一次数据123456789101112@Testpublic void reply_latest() { Sinks.Many&lt;String&gt; sink = Sinks.many().replay().latest(); List&lt;String&gt; list1 = new ArrayList&lt;&gt;(), list2 = new ArrayList&lt;&gt;(); sink.tryEmitNext(&quot;1&quot;); sink.tryEmitNext(&quot;2&quot;); sink.asFlux().subscribe(list1::add); sink.tryEmitNext(&quot;3&quot;); sink.asFlux().subscribe(list2::add); assertThat(list1).isEqualTo(List.of(&quot;2&quot;, &quot;3&quot;)); assertThat(list2).isEqualTo(List.of(&quot;3&quot;));} 对于可能涉及到多线程并发下发元素的问题，Sinks内部通过相关Sink*Serialized线性实现，当并发竞争下发元素时，返回下发失败FAIL_NON_SERIALIZED，开发者可以使用EmitFailureHandler根据返回结果进行相应弹性处理，如重试等，当然EmitFailureHandler使用时需要特别注意，如果失败处理一直返回true的话，很容易陷入死循环，导致CPU占满的。 1234567@Testpublic void multi_thread_sink_emit() { Sinks.Many&lt;String&gt; sink = Sinks.many().unicast().onBackpressureBuffer(); IntStream.range(0, 100) .parallel() .forEach(i -&gt; sink.tryEmitNext(String.valueOf(i)).orThrow()); // Sink emission failed with FAIL_NON_SERIALIZED} 当然Sinks也提供了unsafe的非线性实现，减少并发检测负载，用于一些不需要保证线程安全的场景，比如内部一些操作符如window的实现就是使用Sinks.unsafe创建对应的Many进行元素下发的。 1234@Testpublic void unsafe() { Sinks.Many&lt;String&gt; sink = Sinks.unsafe().many().unicast().onBackpressureBuffer();} 总结本文以Reactor中的Processor的作用开篇，因为Reactor已将相关Processor实现标注为Deprecated，所以本文使用大量篇幅及代码示例讲解了新的Sinks API的使用和相关注意事项，如果你的工程中还在使用**Processor作为编程式下发数据使用，可以考虑升级到3.4.0以上以及使用Sinks全面替换掉旧的实现。 Reference https://github.com/echooymxq/reactive-study https://projectreactor.io/ https://easywheelsoft.github.io/reactor-core-zh/ https://projectreactor.io/docs/core/release/reference/","link":"/2022/04/25/reactor/processor/"},{"title":"使用Reactor进行反应式编程(一)","text":"前言Reactor作为继RxJava之后的又一反应式编程框架的Java实现，由Pivotal(现VMware)创建和维护，作为Spring在反应式编程实现上的基础。在Reactive Streams推出之后，几乎所有JVM之上的反应式编程框架都会遵循它来实现。其实学好反应式编程，最主要的是理解面向数据流，异步非阻塞的编程思想，改变固有面向逻辑思维，接受这种编程范式。其次就是需要掌握某一反应式编程框架，而掌握这个框架就是熟练的使用该框架提供的丰富操作符进行组合使用。很多开发人员在接触Reactor觉得比较困难的原因就是在于不熟悉其操作符，所以本文我们列举大量示例代码挑选部分重要操作符重点讲讲。Reactor使用Mono表示0到1个元素，Flux表示包含0..N个元素，操作符是基于流进行操作的，而涉及流的操作无外乎创建、过滤、拆分、合并、转换等等，本文涉及到的所有源码都已放到Github上。 创建 列举元素创建1Flux&lt;String&gt; source = Flux.just(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;); 依赖外部对象创建123456// 根据某个流创建Flux&lt;String&gt; source = Flux.from(Flux.just(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;));// 根据Stream创建Flux&lt;String&gt; source = Flux.fromStream(Stream.of(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;));// 根据Iterable创建流，例如：List、Set、Queue等等Flux&lt;String&gt; source = Flux.fromIterable(List.of(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;)); 根据数值范围创建12// range(n,m) =&gt; n -&gt; n+m-1Flux&lt;Integer&gt; source = Flux.range(0, 3); 创建一个依靠其它线程周期产生元素的流，正常情况下，流永远不会结束1Flux&lt;Long&gt; source = Flux.interval(Duration.of(1, ChronoUnit.SECONDS)); 使用generate创建流123456789101112131415161718192021222324252627282930Flux&lt;String&gt; source = Flux.generate(sink -&gt; { sink.next(&quot;1&quot;); // 执行过程中只能调用最多一次sink#next sink.complete();});// 进行状态设置final Random random = new Random();Flux&lt;Integer&gt; source = Flux.generate(ArrayList::new, (list, sink) -&gt; { int value = random.nextInt(100); list.add(value); sink.next(value); // 仅创建50个元素 if (list.size() == 50) { sink.complete(); } return list;});// 进行状态设置和流终止时的状态回调final Random random = new Random();Flux&lt;Integer&gt; source = Flux.generate(ArrayList::new, (list, sink) -&gt; { int value = random.nextInt(100); list.add(value); sink.next(value); if (list.size() == 50) { sink.complete(); } return list; }, ArrayList::clear); 使用create创建流1234567// 可以使用同步sink多次或多线程sink#next(即多个生产者)Flux&lt;Integer&gt; source = Flux.create(sink -&gt; { for (int i = 0; i &lt; 100; i++) { sink.next(i); } sink.complete();}); 使用push创建流1234567// 使用push创建流，单线程sink#next(即单个生产者)才能保证线程安全(元素数量大小一致)Flux&lt;Integer&gt; source = Flux.push(sink -&gt; { for (int i = 0; i &lt; 100; i++) { sink.next(i); } sink.complete();}); 使用using创建流12345678Random random = new Random();Flux&lt;?&gt; source = Flux.using(ArrayList::new, list -&gt; { for (int i = 0; i &lt; 100; i++) { int value = random.nextInt(100); list.add(value); } return Flux.fromIterable(list);}, ArrayList::clear); 使用usingWhen创建流1234// 可根据一个Publisher创建流，创建的流Complete时将触发cleanUp回调Flux&lt;String&gt; source = Flux.usingWhen(Mono.just(&quot;a&quot;), e -&gt; Mono.just(e.toUpperCase()), e -&gt; Mono.never()); 过滤 使用filter过滤流中的元素12Flux&lt;String&gt; source = Flux.just(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;) .filter(e -&gt; e.equals(&quot;2&quot;)); 使用take提取流中的元素12345678// 获取流的前N个元素Flux&lt;String&gt; source = Flux.just(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;).take(2);// 获取流的后N个元素Flux&lt;String&gt; source = Flux.just(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;).takeLast(2);// 一直下发元素到满足Predicate条件时(包含满足该条件的当前元素)，将不再继续下发元素Flux&lt;String&gt; source = Flux.just(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;).takeUntil(e -&gt; e.equals(&quot;2&quot;)); // onNext(1), onNext(2)// 只有满足Predicate条件时(只要遇到False都将终止流)，才下发元素Flux&lt;String&gt; source = Flux.just(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;).takeWhile(s -&gt; s.equals(&quot;1&quot;)) // onNext(1) 拆分 使用buffer拆分流的元素为集合列表123456// 按固定大小将元素分批下发到下游Flux&lt;List&lt;String&gt;&gt; source = Flux.just(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;).buffer(2); // 1,2 | 3// 根据Predicate缓冲元素列表再下发到下游,可根据cutBefore参数选择是否丢弃缓冲元素Flux&lt;List&lt;String&gt;&gt; flux = Flux.just(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;).bufferUntil(e -&gt; e.equals(&quot;2&quot;), false); // 1, 2 | 3// 根据Predicate缓冲满足条件的元素到列表中，下发到下游Flux&lt;List&lt;String&gt;&gt; source = Flux.just(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;).bufferWhile(e -&gt; e.equals(&quot;2&quot;)); // 2 使用window把流拆分为多个子流123456// 将流根据window大小拆分为多个子流作为元素进行下发 Flux&lt;Flux&lt;String&gt;&gt; source = Flux.just(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;).window(2); // 1, 2 | 3// 根据Predicate条件，断言为True时将包含当前及前面的元素拆分为子流进行下发Flux.just(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;).windowUntil(e -&gt; e.equals(&quot;2&quot;)); // 1, 2 | 3// 根据Predicate条件，遇到False时将满足条件的元素拆分为子流进行下发Flux&lt;Flux&lt;String&gt;&gt; source = Flux.just(&quot;1&quot;, &quot;2&quot;, &quot;3&quot;).windowWhile(e -&gt; !e.equals(&quot;2&quot;)); // 1 | 3 合并 使用merge合并流的元素123456// 将多个子流合并为一个流，不同流之间元素可能交错，如想保证流顺序，使用mergeSequentialFlux&lt;String&gt; source = Flux.merge(Flux.just(&quot;1&quot;, &quot;2&quot;), Flux.just(&quot;3&quot;));// 将多个子流合并为一个流，并保证不同流之间元素的顺序Flux&lt;String&gt; source = Flux.mergeSequential(Flux.just(&quot;1&quot;, &quot;2&quot;), Flux.just(&quot;3&quot;));// 一个流合并另一个流Flux.just(&quot;1&quot;, &quot;2&quot;).mergeWith(Flux.just(&quot;3&quot;)); 使用reduce合并元素的值12Mono&lt;Integer&gt; source = Flux.just(1, 2, 3).reduce(Integer::sum); // 6Mono&lt;Integer&gt; source = Flux.just(1, 2, 3).reduceWith(() -&gt; 100, Integer::sum); // 106 使用zipWith合并流的元素为元组1234// 合并两个流之间的元素为元组进行下发Flux&lt;Tuple2&lt;String, String&gt;&gt; source1 = Flux.just(&quot;a&quot;, &quot;b&quot;).zipWith(Flux.just(&quot;c&quot;, &quot;d&quot;, &quot;e&quot;)); //// 可对元组进行再操作Flux&lt;String&gt; source2 = Flux.just(&quot;a&quot;, &quot;b&quot;).zipWith(Flux.just(&quot;c&quot;, &quot;d&quot;, &quot;e&quot;), (s1, s2) -&gt; s1 + s2); // ac | bd 转换 使用flatmap转换流的元素123// 并不保证元素的顺序，在意顺序使用concatMapMap&lt;String, String&gt; store = Map.of(&quot;1&quot;, &quot;a&quot;, &quot;2&quot;, &quot;b&quot;);Flux&lt;String&gt; source = Flux.just(&quot;1&quot;, &quot;2&quot;).flatMap(e -&gt; Flux.just(store.get(e))); 使用concatMap转换流的元素123// 保证元素的顺序Map&lt;String, String&gt; store = Map.of(&quot;1&quot;, &quot;a&quot;, &quot;2&quot;, &quot;b&quot;);Flux&lt;String&gt; source = Flux.just(&quot;1&quot;, &quot;2&quot;).concatMap(e -&gt; Flux.just(store.get(e))); // a, b 使用transform转换流的元素123// 将源流转换为目标流再下发到下游，可以将多个对流的操作如map、filter结合作为Function传入Function&lt;Flux&lt;String&gt;, Flux&lt;String&gt;&gt; function = f -&gt; f.filter(color -&gt; !color.equals(&quot;b&quot;)).map(String::toUpperCase);Flux&lt;String&gt; source = Flux.just(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;).transform(function); // A, C 使用handle转换流的元素12Flux&lt;String&gt; source = Flux.just(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;) .handle((s, sink) -&gt; sink.next(s.toUpperCase())); 使用switchOnFirst转换流123456789// 将流转换为第一个元素和原始流的组合，通常可根据第一个元素决定相关操作Flux&lt;String&gt; source = Flux.just(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;) .switchOnFirst(((firstVal, flux) -&gt; { String val = firstVal.get(); if (&quot;a&quot;.equals(val)) { return flux.take(2); // 如果流以a开头，只获取前两个元素，否则返回原始流 } return flux; })); Reference https://github.com/echooymxq/reactive-study https://projectreactor.io/ https://easywheelsoft.github.io/reactor-core-zh/ https://projectreactor.io/docs/core/release/reference/","link":"/2022/04/24/reactor/reactor/"},{"title":"使用Reactor进行反应式编程(二)","text":"我们通常认为Reactor是异步非阻塞的，这一节我们来聊聊它的线程和调度器。Reactor被认为是并发不可知论的，即它并没有强制规定执行哪一个线程模型。相反，Reactor有自己的Scheduler并发抽象，能够让开发人员自己控制线程执行情况。 线程调度器首先Reactive Stream的生命周期分为三个阶段，组装(Assembling)、订阅(Subscription)和运行(Runtime)。 组装(Assembling)组装阶段为Publisher的声明和初始化阶段，如下所示： 12Mono&lt;String&gt; source = Mono.just(&quot;a&quot;,&quot;b&quot;,&quot;c&quot;) .map(String::toUpperCase); 订阅(Subscription)在组装阶段只是定义Publisher和组合操作，在订阅.subscribe()方法之前什么都不会发生，订阅阶段对应执行Publisher#subscribe和Subscriber#onSubscribe。 运行(Runtime)在订阅之后，整个阶段对应执行Subscription#request和Subscriber#onNext/onComplete/onError。 而如果我们要关注Reactor的线程执行情况，则只需要注意上面三个阶段即可。Reactor自带了几个Scheduler的默认实现： Schedulers.immediate()在提交的线程上立即执行任务，查看其内部实现是直接将Runnable执行的，那为什么还需要这个实现呢？首先该Scheduler很少会使用到，通常用于需要Scheduler传参但不想改变执行线程的一些API上，如Flux#publishOn(scheduler,prefetch)用于实现背压的，但是下发元素又想在当前线程上执行，Flux#limitRate就是基于此实现的。 1234Flux.range(1,3) .publishOn(Schedulers.immediate(),2) //背压每次读取两个元素，要求不改变线程；此处可以直接替换为limitRate(2) .log() .subscribe(); Schedulers.single()全局可重用只包含单个线程的调度器，所有调用者都会共用相同的线程。 Schedulers.elastic()全局无界的弹性调度器，可以无限的创建线程，在有了Schedulers.boundedElastic()之后，已被弃用(Deprecated)。 Schedulers.boundedElastic()全局有界的弹性调度器，默认最大线程数为10倍CPU核数，默认单个线程任务队列数为100000。 Schedulers.parallel()全局固定大小的调度器，默认大小为CPU核数。 single为一些操作想要执行在一个特定的线程上所使用；而内部的一些时间相关的操作符（如delay、timeout和bufferTimeout等等）则是用parallel作为默认调度器；boundedElastic通常则是用于一些长耗时的任务，特别是涉及到IO阻塞调用，另外上面的调度器除了immediate之外，所有其它的调度器均可使用Scheduler#new**单独创建一个新的实例。 subscribeOn和publishOn的区别前面我们说过Reactor是并发不可知论的，Reactor通常是在调用subscribe的那个线程上运行的（排除时间相关操作符），但也提供了其它的方式来切换上下文执行线程的。 publishOnpublishOn应用在调用链中间的某个位置，用于切换下发到下游元素的上下文线程，导致onNext/onComplete/onError在该线程上执行，影响的是该位置后续的操作符。123456789101112@Testpublic void publishOn() { Flux&lt;String&gt; source = Flux.just(&quot;a&quot;) .doOnNext(s -&gt; System.out.println(Thread.currentThread().getName())) //main.. .publishOn(Schedulers.boundedElastic()) // 切换下游上下文执行线程 .doOnNext(s -&gt; System.out.println(Thread.currentThread().getName())) // boundedElastic... .log() .map(String::toUpperCase); StepVerifier.create(source) .expectNext(&quot;A&quot;) .verifyComplete();} 存在多个publishOn时，线程切换的影响范围为到下一个publishOn的位置。12345678910111213@Testpublic void multi_publishOn() { Flux&lt;String&gt; source = Flux.just(&quot;a&quot;) .publishOn(Schedulers.parallel()) // 切换下游上下文执行线程 .doOnNext(s -&gt; System.out.println(Thread.currentThread().getName())) //parallel.. .publishOn(Schedulers.boundedElastic()) // 切换下游上下文执行线程 .doOnNext(s -&gt; System.out.println(Thread.currentThread().getName())) // boundedElastic... .log() .map(String::toUpperCase); StepVerifier.create(source) .expectNext(&quot;A&quot;) .verifyComplete();} subscribeOnsubscribeOn用于切换执行订阅的上下文线程，导致Publisher#subscribe、Subscriber#onSubscribe和Subscription#request，以及后续的onNext/onError/onComplete事件也会在该线程上执行。subscribeOn的位置并不会影响到其实际作用效果，因为订阅始终是从下游传递到上游的。123456789101112@Testpublic void subscribeOn() { Flux&lt;String&gt; source = Flux.just(&quot;a&quot;) .log() .map(String::toUpperCase)// .subscribeOn(Schedulers.boundedElastic()) .doOnNext(s -&gt; System.out.println(Thread.currentThread().getName())) // boundedElastic...，subscribeOn不管是在doOnNext的上游还是下游，效果一样的 .subscribeOn(Schedulers.boundedElastic()); StepVerifier.create(source) .expectNext(&quot;A&quot;) .verifyComplete();} 存在多个subscribeOn时，采用的总是离上游最近的那个调度器。123456789101112@Testpublic void multi_subscribeOn() { Flux&lt;String&gt; source = Flux.just(&quot;a&quot;) .log() .map(String::toUpperCase) .doOnNext(s -&gt; System.out.println(Thread.currentThread().getName()))//Schedulers.parallel()离上游最近，使用Schedulers.parallel调度器线程执行 .subscribeOn(Schedulers.parallel()) .subscribeOn(Schedulers.boundedElastic()); StepVerifier.create(source) .expectNext(&quot;A&quot;) .verifyComplete();} subscribeOn和publishOn结合使用时，subscribeOn改变的是上游到publishOn位置的上下文线程，publishOn则是改变的该位置后续的执行线程。12345678910111213@Testpublic void subscribeOn_with_publishOn() { Flux&lt;String&gt; source = Flux.just(&quot;a&quot;) .doOnNext(s -&gt; System.out.println(Thread.currentThread().getName())) //parallel.. .publishOn(Schedulers.boundedElastic()) // 切换下游上下文执行线程 .doOnNext(s -&gt; System.out.println(Thread.currentThread().getName())) // boundedElastic... .log() .map(String::toUpperCase) .subscribeOn(Schedulers.parallel()); StepVerifier.create(source) .expectNext(&quot;A&quot;) .verifyComplete();} subscribeOn和publishOn的区别在于改变执行线程的范围不一样，其Javadoc有分别描述具体两者的使用场景。subscribeOn通常用于慢生产者-快消费者，慢生产者为例如阻塞IO等时，使用subscribeOn则可以切换订阅上下文线程，防止阻塞调用subscribe操作的线程。而publishOn通常用于快生产者-慢消费者，其内部包含一个队列用于缓冲上游的发布的元素。 永远不要阻塞”非阻塞线程”线程资源是珍贵的，系统应用中通常使用线程池维护有限的线程数量来执行并行任务，我们要避免编写阻塞式代码，从而导致任务线程阻塞、系统资源利用率降低。Reactor的编程模型就是异步非阻塞的，所以不要在Reactor上下文中使用阻塞式API，其本身也做了部分限制，只要实现了NonBlocking接口的线程对象，都会被当作非阻塞线程，如在默认的single和parallel的调度器中，不允许使用block操作，如下所示: 12345678910111213@Testpublic void block_non_blocking_thread() { Mono&lt;String&gt; source = Mono.just(&quot;a&quot;) .delayElement(Duration.ofMillis(10)) // delay等时间相关操作符默认使用parallel Scheduler，创建的线程实例为非阻塞线程不允许使用block// .publishOn(Schedulers.boundedElastic()) .map(s -&gt; convert(s).block()); // java.lang.IllegalStateException: block()/blockFirst()/blockLast() are blocking, which is not supported in thread parallel StepVerifier.create(source) .expectNext(&quot;A&quot;) .verifyComplete();}public static Mono&lt;String&gt; convert(String a) { return Mono.defer(() -&gt; Mono.just(a.toUpperCase()));} 如果我们在某些情况下一定需要在Reactor上下文中使用block操作的话，可以使用publishOn将其切换到boundedElastic或者其它自定义调度器中执行。 总结本文我们了解了Reactor的几种默认线程调度器，并基于Reactive Stream的生命周期，讲述了subscribeOn和publishOn切换上下文线程对应的不同阶段及其差异。在使用Reactor进行反应式编程时，我们通常不需要关心对应执行在哪个线程，但作为开发人员需要了解Reactor并发机制，并且永远不要阻塞”非阻塞”线程，从而导致系统资源饥饿。 Reference https://github.com/echooymxq/reactive-study https://projectreactor.io/ https://easywheelsoft.github.io/reactor-core-zh/ https://projectreactor.io/docs/core/release/reference/","link":"/2022/04/25/reactor/scheduler/"},{"title":"git_tips之配置覆盖","text":"几乎每个开发都会有两个及其以上的git账户，包括个人的Github账户和公司的Gitlab账户，而我们经常需要在个人项目和工作项目之间互相切换，有时候会在工作项目下使用git config --local user.name xxx和git config --local user.email xxx@xxx.com进行设置。但是由于Project比较多，全局的git配置为个人项目配置，有时经常忘记切换和设置，导致将个人项目的用户信息提交到工作项目中，所以经常会花费太多时间在修改错误的commit信息上。 配置如下： 123456#~/.gitconfig 全局配置[user] name = xxx email = xxx@gmail.com[includeIf &quot;gitdir:~/repo/company/&quot;] path = ~/repo/company/.gitconfig 1234#~/repo/company/.gitconfig 工作目录配置[user] name = work-name email = work-email@xxx.com 进行如上配置后，在工作目录下的用户配置会覆盖掉全局的用户配置，而在其它目录下，还是继续使用默认的全局配置。PS: includeIf选项要求git版本&gt;=2.13.7。","link":"/2022/04/10/tools/git_tips1/"},{"title":"git_tips之修改提交","text":"通常我们在使用git进行本地提交时，当提交后发现还需要修改部分文件内容或者少提交文件时，再次commit时可能会多生成一条commit。Git有一个修改先前提交的选项--amend可以帮助我们少生成这次commit，如下所示: 1234# 添加修改的文件或上次commit落下的文件$ git add .# 直接合并到上次的commit中$ git commit --amend --no-edit 如果这次提交时还需要修改上次的commit信息，那么去掉--no-edit选项，使用git commit --amend后vi修改commit信息保存即可。 对于--amend，部分IDEA也是有支持的，以IntelliJ IDEA为例，如下所示： 上述方式我们通常只能够修改最后一次的提交，如果需要修改多个提交信息，就需要git rebase -i变基来做到。注意：不论是使用git commit --amend还是git rebase前提都是commit未push到远程。 Reference https://git-scm.com/book/en/v2/Git-Tools-Rewriting-History","link":"/2022/04/14/tools/git_tips2/"},{"title":"我为什么会用httpie?","text":"前不久HTTPie由于不小心将其仓库私有化，导致项目十年来的Star数目全部丢失。虽然项目组找到Github官方寻求帮助希望恢复数据，却未能如愿。周末的时候看到官方博客发的这篇事后分析文章How we lost 54k GitHub stars，作者从UI、数据库设计到社区关系等问题进行了反思。其实作为一个CLI工具能排进Github TOP100是非常优秀的。基于平时经常使用httpie进行HTTP接口调测，特地写一篇httpie和其它工具简单比较的文章。 如果工作中平时涉及到WEB HTTP接口开发，那么在调试API接口时肯定会使用到某种HTTP客户端工具。最常用的有curl、postman或者编写.httpfile结合idea扩展进行调测，还有上面提到的httpie。 curl应该是所有人接触到的第一个HTTP客户端工具，通常linux系统中都会自带curl命令，可能有些人对curl的认知还只停留在http客户端工具上，如果用man命令查看curl，会发现curl异常强大，支持各种常见协议，如telnet、mqtt等等。如下所示为用curl代替telnet测试端口连通性： 123$ curl -vv telnet://192.168.1.101:80# * Trying 192.168.1.101:80...# * Connected to 192.168.1.101 (192.168.1.101) port 80 (#0) 正因为其功能强大，导致使用上相对会比较复杂繁琐。例如：在进行POST提交json时，总是需要添加-H 'Content-Type: application/json'，因为-d, --data默认是以表单方式application/x-www-form-urlencoded进行提交，这会让整个命令显得非常冗余。值得开心的是，官方在2022/03/05发布最新的版本7.82.0中添加了--json选项增强了对json的支持，详情查看changelog，简单地说，以后可以不需要使用-d和-H 'Content-Type: application/json'来提交json了，如下所示： 1234# 7.82.0版本之前$ curl -X POST 'localhost:80/anything' -H 'Content-Type: application/json' -d '{&quot;name&quot;:&quot;echooymxq&quot;}'# 7.82.0版本开始$ curl -X POST 'localhost:80/anything' --json '{&quot;name&quot;: echooymxq}' postmanpostman应该是绝大多数人日常用的，它也不再仅仅是一个HTTP客户端工具，而是一个API文档、调试、Mock、自动化测试协同平台，有Workspace和Collections等概念，Code功能能够将HTTP请求转换生成其他第三方代码，然而对我吸引最大的还是它支持GraphQL。 http clientjetbrains的HTTP Client插件允许在IDEA中创建编辑.http和.rest文件，并直接发起HTTP请求。如下所示：比较让人吸引的一点是，可以在编写代码的时候直接编写HTTP测试请求，并且可以和代码放在一个repo下进行管理。 httpiehttpie作为一个终端CLI，和curl使用上基本没有太大的区别，但是它大大的简化了使用语法，降低了使用者的心智负担，并且还支持语法高亮，下面简单列举几点： 默认请求schema为http://，这点和curl保持一致，具体在使用时可省略schema 1$ http localhost:80/get 方法是可选的，当有body参数时，默认为POST，没有body时，默认为GET，方法名不区分大小写。 12$ http localhost:80/get$ http POST localhost:80/post 查询参数为name==value，Header为Name:Value，请求json用法field=value，加--form, -f为表单提交 12345678# 查询参数，等价于http://localhost/get?id=1$ http localhost:80/get id==1# 添加Header，X-Date today$ http localhost:80/get X-Date:today id==1# 提交jsob请求体 {&quot;name&quot;:&quot;echooymxq&quot;}$ http post localhost:80/post name=echooymxq# 以表单方式提交&quot;name&quot;: &quot;echooymxq&quot;$ http post localhost:80/post name=echooymxq -f 省略localhost，在本地开发时，这点是我最喜欢的了，再也不用写localhost了。 1234# 省略localhost$ http :80/get# 如果端口是80，可以省略端口$ http :/get 总结有了curl，为什么还需要httpie？curl因为强大的功能和复杂的协议支持，平时在使用的时候需要记住比较多的选项和编写较长的命令。而httpie专注于HTTP，大大简化了使用者的操作，使得发起一个HTTP请求非常简单和轻量。jetbrains支持的HTTP Client在日常也用得非常多，它主要能够像代码一样编写和维护API调测用例。而postman，桌面版的使用就显得相对比较繁重了。相较于curl和httpie，postman和国内一些商业公司的产品如apifox，都是在朝着API开放平台来做，就连httpie也在推出自己的桌面和WEB版。综上，httpie是一个非常不错的库，在日常用它调试API接口是非常方便的。 本文所有调用的测试服务接口均为在本机使用docker启动httpbin提供。 Reference https://httpbin.org/ https://httpie.io/docs/cli https://daniel.haxx.se/blog/2022/02/02/curl-dash-dash-json/","link":"/2022/04/15/tools/httpie/"}],"tags":[{"name":"reactive","slug":"reactive","link":"/tags/reactive/"},{"name":"git","slug":"git","link":"/tags/git/"},{"name":"tools","slug":"tools","link":"/tags/tools/"}],"categories":[{"name":"reactive","slug":"reactive","link":"/categories/reactive/"},{"name":"tools","slug":"tools","link":"/categories/tools/"}]}